{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "import requests\n",
    "from dbfread import DBF\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo SINASC2016.csv carregado e concatenado.\n",
      "Arquivo SINASC2017.csv carregado e concatenado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\João Miguel\\AppData\\Local\\Temp\\ipykernel_14324\\2851265950.py:53: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path, sep=';', encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo SINASC2018.csv carregado e concatenado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\João Miguel\\AppData\\Local\\Temp\\ipykernel_14324\\2851265950.py:53: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path, sep=';', encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo SINASC2019.csv carregado e concatenado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\João Miguel\\AppData\\Local\\Temp\\ipykernel_14324\\2851265950.py:53: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path, sep=';', encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo SINASC2020.csv carregado e concatenado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\João Miguel\\AppData\\Local\\Temp\\ipykernel_14324\\2851265950.py:53: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path, sep=';', encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo SINASC2021.csv carregado e concatenado.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODMUNNASC</th>\n",
       "      <th>DTNASC</th>\n",
       "      <th>RACACORMAE</th>\n",
       "      <th>RACACOR</th>\n",
       "      <th>DTNASCMAE</th>\n",
       "      <th>IDADEMAE</th>\n",
       "      <th>IDANOMAL</th>\n",
       "      <th>CODANOMAL</th>\n",
       "      <th>id_ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110020</td>\n",
       "      <td>18022016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10081986.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110020</td>\n",
       "      <td>28012016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19032001.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110020</td>\n",
       "      <td>25022016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13081985.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110020</td>\n",
       "      <td>20042016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15091992.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110020</td>\n",
       "      <td>27042016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10071985.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982654</th>\n",
       "      <td>530010</td>\n",
       "      <td>19092021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5031988.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982655</th>\n",
       "      <td>530010</td>\n",
       "      <td>30102021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10051994.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982656</th>\n",
       "      <td>530010</td>\n",
       "      <td>21092021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3031995.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982657</th>\n",
       "      <td>530010</td>\n",
       "      <td>1122021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21121984.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982658</th>\n",
       "      <td>530010</td>\n",
       "      <td>8122021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21121990.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16982659 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CODMUNNASC    DTNASC  RACACORMAE  RACACOR   DTNASCMAE  IDADEMAE  \\\n",
       "0             110020  18022016         1.0      1.0  10081986.0      29.0   \n",
       "1             110020  28012016         4.0      4.0  19032001.0      14.0   \n",
       "2             110020  25022016         4.0      4.0  13081985.0      30.0   \n",
       "3             110020  20042016         4.0      4.0  15091992.0      23.0   \n",
       "4             110020  27042016         4.0      4.0  10071985.0      30.0   \n",
       "...              ...       ...         ...      ...         ...       ...   \n",
       "16982654      530010  19092021         1.0      1.0   5031988.0      33.0   \n",
       "16982655      530010  30102021         4.0      4.0  10051994.0      27.0   \n",
       "16982656      530010  21092021         2.0      2.0   3031995.0      26.0   \n",
       "16982657      530010   1122021         NaN      NaN  21121984.0      36.0   \n",
       "16982658      530010   8122021         4.0      4.0  21121990.0      30.0   \n",
       "\n",
       "          IDANOMAL CODANOMAL  id_ano  \n",
       "0              2.0       NaN    2016  \n",
       "1              2.0       NaN    2016  \n",
       "2              2.0       NaN    2016  \n",
       "3              2.0       NaN    2016  \n",
       "4              2.0       NaN    2016  \n",
       "...            ...       ...     ...  \n",
       "16982654       2.0       NaN    2021  \n",
       "16982655       9.0       NaN    2021  \n",
       "16982656       2.0       NaN    2021  \n",
       "16982657       2.0       NaN    2021  \n",
       "16982658       2.0       NaN    2021  \n",
       "\n",
       "[16982659 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################\n",
    "## Nome da tabela que será inputada/atualizada no banco de dados ##\n",
    "###################################################################\n",
    "\n",
    "# Nome que da tabela para o SQL\n",
    "nome_tabela = 'tb_sinasc_dn'\n",
    "\n",
    "# Pasta onde os dados estão armazenados\n",
    "folder_path = 'C:\\Programacao\\Python Scripts\\dado_tratado'\n",
    "# Iniciais do arquivo\n",
    "arquivo = 'SINASC'\n",
    "\n",
    "# Seleção das variáveis\n",
    "variaveis_selecionadas = [\n",
    "                        'CODMUNNASC',\n",
    "                        'DTNASC',\n",
    "                        'RACACORMAE',\n",
    "                        'RACACOR',\n",
    "                        'DTNASCMAE',\n",
    "                        'IDADEMAE',\n",
    "                        'IDANOMAL',\n",
    "                        'CODANOMAL'\n",
    "                        ]\n",
    "\n",
    "\n",
    "def tratamento(df):\n",
    "    df['id_ano'] = df['DTNASC']%10000\n",
    "    return df\n",
    "\n",
    "\n",
    "###################################################################\n",
    "## Código para carregar, selecionar variáveis e inputar no Banco ##\n",
    "###################################################################\n",
    "\n",
    "\n",
    "# Criar uma variável para substituir `pasta` com o caminho do arquivo\n",
    "def dbf_to_dataframe(pasta): \n",
    "    # Lista vazia\n",
    "    dados = []\n",
    "    # Ler o DBF e fazer append na lista vazia\n",
    "    for dado in DBF(pasta, encoding='latin1'):\n",
    "        dados.append(dado)\n",
    "\n",
    "    # Converter em dadosframe\n",
    "    return pd.DataFrame(dados)\n",
    "\n",
    "\n",
    "# Função para ler o arquivo com base na extensão\n",
    "def pandas_read(file_path):\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "    \n",
    "    if file_extension == '.csv':\n",
    "        return pd.read_csv(file_path, sep=';', encoding='latin1')\n",
    "    elif file_extension == '.dbf':\n",
    "        return dbf_to_dataframe(file_path)  # Substitua a função dbf_to_dataframe pela função correta para ler arquivos .dbf\n",
    "    else:\n",
    "        raise ValueError(f\"Tipo de arquivo não suportado: {file_extension}\")\n",
    "\n",
    "# DataFrame vazio para armazenar os dados concatenados\n",
    "concatenated_df = pd.DataFrame()\n",
    "\n",
    "# Loop nos arquivos no diretório \n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.startswith(arquivo) and (filename.endswith('.csv') or filename.endswith('.dbf')):\n",
    "        file_path = os.path.join(folder_path, filename)             # Construção do caminho completo\n",
    "        df = pandas_read(file_path)                                 # Leitura do arquivo\n",
    "        \n",
    "        # Lista de colunas selecionadas (adicione as colunas desejadas aqui)\n",
    "        df = df[variaveis_selecionadas]\n",
    "        \n",
    "        df = tratamento(df)\n",
    "\n",
    "        treated_df = df.copy()                                      # Aplica a função que retorna o mesmo df\n",
    "        concatenated_df = pd.concat([concatenated_df, treated_df])\n",
    "\n",
    "        print(f\"Arquivo {filename} carregado e concatenado.\")\n",
    "# Reset index e concatenando em um DataFrame\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display do DataFrame concatenado\n",
    "display(concatenated_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "## Configurações do banco de dados ##\n",
    "#####################################\n",
    "\n",
    "db_config = {\n",
    "    'host': 'ls-5ae56aeb2ca5d6cbcd113e0c1aaa14c2a5395de9.c1ozwzg2gdjm.us-east-1.rds.amazonaws.com',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgresql_vs_public',\n",
    "    'password': '>D,&g-5ZURExX=e-t]8?UXL2j!9B;xtc',\n",
    "}\n",
    "\n",
    "# Código que tenta conectar ao banco e carregar o dataframe\n",
    "try:\n",
    "    # Conecta ao banco de dados usando o SQLAlchemy\n",
    "    engine = create_engine(f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}/{db_config['database']}\")\n",
    "\n",
    "    # Carrega o DataFrame para o banco de dados\n",
    "    concatenated_df.to_sql(nome_tabela, engine, if_exists='replace', index=False) # alterar \"replace\" no if_exists para \"append\" e testar com as novas variaveis\n",
    "\n",
    "    # Caso dê certo\n",
    "    print(\"Dados carregados com sucesso!\")\n",
    "\n",
    "    # Caso não dê certo\n",
    "except (psycopg2.Error, Exception) as e:\n",
    "    print(\"Erro ao conectar ao PostgreSQL ou carregar os dados:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
